{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CMPE-258-Assignment-7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP4hHYNca5RYUV708bn6J20",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagrutimohanty/CMPE-258-DeepLearning/blob/main/Assignment7/CMPE_258_Assignment_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbkvG8x3WuoX"
      },
      "source": [
        "Name : Jagruti Mohanty\n",
        "Assignment 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic0HPGQ6DOew"
      },
      "source": [
        "# Part B) mnist classification using RNNs where you are passing MNIST image data row by row to rnns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJM8JsRw16Gn",
        "outputId": "0edfa36e-2c71-4148-b90c-ecb482c72770"
      },
      "source": [
        "!pip install watermark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting watermark\n",
            "  Downloading https://files.pythonhosted.org/packages/73/71/8a7c1c1672bc20448ef8b96652f7d332bd680a4b2e873f50ea1e4ede81ca/watermark-2.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from watermark) (5.5.0)\n",
            "Collecting importlib-metadata<3.0; python_version < \"3.8\"\n",
            "  Downloading https://files.pythonhosted.org/packages/98/b8/8ec57a8ef46fbe7f185318c7ff7df9a06c9df451d9a59a067bfa851bb828/importlib_metadata-2.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (5.0.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (56.0.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (0.7.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<3.0; python_version < \"3.8\"->watermark) (3.4.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->watermark) (0.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->watermark) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->watermark) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->watermark) (0.7.0)\n",
            "Installing collected packages: importlib-metadata, watermark\n",
            "  Found existing installation: importlib-metadata 3.10.1\n",
            "    Uninstalling importlib-metadata-3.10.1:\n",
            "      Successfully uninstalled importlib-metadata-3.10.1\n",
            "Successfully installed importlib-metadata-2.1.1 watermark-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a1E0j7Pyupl"
      },
      "source": [
        "# Import MNIST DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi4p6I0nAGdB"
      },
      "source": [
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "sample, sample_label = x_train[4], y_train[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH4JHMmK_OXL"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTeV11DDyyVw"
      },
      "source": [
        "# Model using LSTM layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzmCjl-f_dZz",
        "outputId": "3e3a265f-8a61-464d-d01b-d4088976097f"
      },
      "source": [
        "model = keras.Sequential()\n",
        "# Add an Embedding layer expecting input vocab of size 1000, and\n",
        "# output embedding dimension of size 64.\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# Add a LSTM layer with 128 internal units.\n",
        "model.add(layers.LSTM(128))\n",
        "\n",
        "# Add a Dense layer with 10 units.\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 164,106\n",
            "Trainable params: 164,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN0BMHxwy2Sp"
      },
      "source": [
        "# Model using GRU and simpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FTfBrVr_jH9",
        "outputId": "9c1a9007-8523-44de-ad03-6c2fd02e1ea3"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "model.add(layers.GRU(256, return_sequences=True))\n",
        "\n",
        "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "model.add(layers.SimpleRNN(128))\n",
        "\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, None, 256)         247296    \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 128)               49280     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 361,866\n",
            "Trainable params: 361,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O4uKJ3Dy-F1"
      },
      "source": [
        "# Model build with RNN(cudnn kernel with LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNInOW52__MB"
      },
      "source": [
        "batch_size = 64\n",
        "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
        "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
        "input_dim = 28\n",
        "\n",
        "units = 64\n",
        "output_size = 10  # labels are from 0 to 9\n",
        "\n",
        "# Build the RNN model\n",
        "def build_model(allow_cudnn_kernel=True):\n",
        "    # CuDNN is only available at the layer level, and not at the cell level.\n",
        "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
        "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
        "    if allow_cudnn_kernel:\n",
        "        # The LSTM layer with default options uses CuDNN.\n",
        "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
        "    else:\n",
        "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
        "        lstm_layer = keras.layers.RNN(\n",
        "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
        "        )\n",
        "    model = keras.models.Sequential(\n",
        "        [\n",
        "            lstm_layer,\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(output_size),\n",
        "        ]\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R5x7C-ZARIT",
        "outputId": "10fbc689-6919-428f-e3cb-c03ce123171e"
      },
      "source": [
        "model = build_model(allow_cudnn_kernel=True)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 23s 22ms/step - loss: 1.3583 - accuracy: 0.5645 - val_loss: 0.6980 - val_accuracy: 0.7705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f97a80148d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cintn2wzQLD"
      },
      "source": [
        "#Output of prediction model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "AiytlXL5AcXs",
        "outputId": "c0a80abf-c59e-4db6-b33b-bb492fe5cc12"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with tf.device(\"CPU:0\"):\n",
        "    cpu_model = build_model(allow_cudnn_kernel=True)\n",
        "    cpu_model.set_weights(model.get_weights())\n",
        "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
        "    print(\n",
        "        \"Predicted result is: %s, target result is: %s\" % (result.numpy(), sample_label)\n",
        "    )\n",
        "    plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted result is: [9], target result is: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAZXxJcizZ2i"
      },
      "source": [
        "# Part E) Build a timeseries forcasting model using RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyAKyFqnGBRx"
      },
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import *\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrfEKOKtGRHW"
      },
      "source": [
        "#Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LQmR4IvGlrV"
      },
      "source": [
        "#Get the Shareable file link and get the contents\n",
        "downloaded = drive.CreateFile({'id':\"1ntWVLwERS_OVcn1yxIrDtjp05JW1skGZ\"})   \n",
        "downloaded.GetContentFile('TSLA.csv')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "yygvT1YFGGdM",
        "outputId": "fc18bc03-f262-42a9-f3f3-29f445b6ce69"
      },
      "source": [
        "df=pd.read_csv(\"TSLA.csv\")\n",
        "#print(‘Number of rows and columns:’, df.shape)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-07-10</td>\n",
              "      <td>52.444000</td>\n",
              "      <td>52.599998</td>\n",
              "      <td>51.563999</td>\n",
              "      <td>51.830002</td>\n",
              "      <td>51.830002</td>\n",
              "      <td>13054500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-07-13</td>\n",
              "      <td>52.450001</td>\n",
              "      <td>52.509998</td>\n",
              "      <td>51.209999</td>\n",
              "      <td>52.431999</td>\n",
              "      <td>52.431999</td>\n",
              "      <td>14801500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-07-14</td>\n",
              "      <td>52.419998</td>\n",
              "      <td>53.198002</td>\n",
              "      <td>52.102001</td>\n",
              "      <td>53.130001</td>\n",
              "      <td>53.130001</td>\n",
              "      <td>9538000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-07-15</td>\n",
              "      <td>53.348000</td>\n",
              "      <td>53.498001</td>\n",
              "      <td>52.416000</td>\n",
              "      <td>52.627998</td>\n",
              "      <td>52.627998</td>\n",
              "      <td>10108000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-07-16</td>\n",
              "      <td>52.844002</td>\n",
              "      <td>53.439999</td>\n",
              "      <td>52.632000</td>\n",
              "      <td>53.335999</td>\n",
              "      <td>53.335999</td>\n",
              "      <td>8080000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close    Volume\n",
              "0  2015-07-10  52.444000  52.599998  51.563999  51.830002  51.830002  13054500\n",
              "1  2015-07-13  52.450001  52.509998  51.209999  52.431999  52.431999  14801500\n",
              "2  2015-07-14  52.419998  53.198002  52.102001  53.130001  53.130001   9538000\n",
              "3  2015-07-15  53.348000  53.498001  52.416000  52.627998  52.627998  10108000\n",
              "4  2015-07-16  52.844002  53.439999  52.632000  53.335999  53.335999   8080000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEgHubi4HLUu"
      },
      "source": [
        "training_set = df.iloc[:800, 1:2].values\n",
        "test_set = df.iloc[800:, 1:2].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spPOwA_DHPtc"
      },
      "source": [
        "# Feature Scaling\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "training_set_scaled = sc.fit_transform(training_set)\n",
        "# Creating a data structure with 60 time-steps and 1 output\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(60, 800):\n",
        "    X_train.append(training_set_scaled[i-60:i, 0])\n",
        "    y_train.append(training_set_scaled[i, 0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "#(740, 60, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBbBBgYhHzZg",
        "outputId": "a1e88e1f-19d5-4bb5-cdc0-bf4b3df1ef76"
      },
      "source": [
        "model = Sequential()\n",
        "#Adding the first LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "model.add(Dropout(0.2))\n",
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(units = 50, return_sequences = True))\n",
        "model.add(Dropout(0.2))\n",
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(units = 50, return_sequences = True))\n",
        "model.add(Dropout(0.2))\n",
        "# Adding a fourth LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(units = 50))\n",
        "model.add(Dropout(0.2))\n",
        "# Adding the output layer\n",
        "model.add(Dense(units = 1))\n",
        "\n",
        "# Compiling the RNN\n",
        "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "# Fitting the RNN to the Training set\n",
        "model.fit(X_train, y_train, epochs = 100, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 8s 104ms/step - loss: 0.1415\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0178\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0155\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.0132\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0121\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0133\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0119\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0106\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0098\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0143\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0113\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0110\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0089\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0104\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.0098\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0081\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0089\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0085\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0075\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.0075\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0067\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0064\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.0076\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.0066\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0071\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.0066\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.0072\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.0068\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0068\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0064\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 3s 109ms/step - loss: 0.0058\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.0074\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0063\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.0062\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0054\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0056\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0055\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0070\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0048\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0047\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0052\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0058\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0049\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0043\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0041\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0061\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0047\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0066\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0041\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0045\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 3s 114ms/step - loss: 0.0045\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0042\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0040\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.0049\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0045\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0042\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0045\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0037\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0041\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0051\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0051\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0038\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0042\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0038\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0039\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0037\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 3s 114ms/step - loss: 0.0036\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0038\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0035\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0035\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0034\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0032\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0040\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0036\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0035\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0034\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0034\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0042\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0034\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0033\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0046\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0033\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0039\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0043\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0034\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 3s 115ms/step - loss: 0.0036\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0040\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0032\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0035\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0032\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 3s 112ms/step - loss: 0.0029\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0029\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0028\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0029\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0028\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0028\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0036\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 3s 111ms/step - loss: 0.0032\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0037\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 3s 113ms/step - loss: 0.0026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5fe8928810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-q0GX5_H9FO",
        "outputId": "f3dbe2dc-0c39-4950-e4a4-60ca20626084"
      },
      "source": [
        "# Getting the predicted stock price of 2017\n",
        "dataset_train = df.iloc[:800, 1:2]\n",
        "dataset_test = df.iloc[800:, 1:2]\n",
        "dataset_total = pd.concat((dataset_train, dataset_test), axis = 0)\n",
        "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "inputs = inputs.reshape(-1,1)\n",
        "inputs = sc.transform(inputs)\n",
        "X_test = []\n",
        "for i in range(60, 519):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "print(X_test.shape)\n",
        "# (459, 60, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(459, 60, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK3ASSPMICJd"
      },
      "source": [
        "predicted_stock_price = model.predict(X_test)\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "t5QKMyHEILlR",
        "outputId": "ba0291d2-6bdc-4717-8769-de50d0c87641"
      },
      "source": [
        "# Visualising the results\n",
        "plt.plot(df.loc[800:, 'Date'],dataset_test.values, color = 'red', label = 'Real TESLA Stock Price')\n",
        "plt.plot(df.loc[800:, 'Date'],predicted_stock_price, color = 'blue', label = 'Predicted TESLA Stock Price')\n",
        "plt.xticks(np.arange(0,459,50))\n",
        "plt.title('TESLA Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('TESLA Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOTkbLP1JMNz"
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(60, 800):\n",
        "    X_train.append(training_set_scaled[i-60:i, 0])\n",
        "    y_train.append(training_set_scaled[i, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDEWOqjkJUON"
      },
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "for i in range(60, 519):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtWZN4Yoz3cQ"
      },
      "source": [
        " # Part C)Build an android studio app using tflite model  for simple colab based trained keras model usecase. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hRSaSBp0Jgp"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpDIASJIGAPp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djUOnrffGTkp"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3dFQxllGWYZ",
        "outputId": "0c5a6ee8-607c-4660-85c1-7fcb651dbb35"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7QfDayDGmsv",
        "outputId": "99ad586c-ac19-49e9-f44f-7f906d813e84"
      },
      "source": [
        "!ls '/content/drive/MyDrive/CMPE-258-Jagruti Mohanty/iris.data'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/drive/MyDrive/CMPE-258-Jagruti Mohanty/iris.data'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-RTKbIFFdkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb57231-8b6a-48d3-ebd8-a7785138206d"
      },
      "source": [
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/CMPE-258-Jagruti Mohanty/iris.data',sep=',')\n",
        "\n",
        "X = df.iloc[:, :4].values\n",
        "y = df.iloc[:, 4].values\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "y = le.fit_transform(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(64, activation='relu', input_shape=[4]))\n",
        "model.add(Dense(64))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "\n",
        "model.fit(X, y, epochs=200)\n",
        "\n",
        "\n",
        "from tensorflow import lite\n",
        "converter = lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "tfmodel = converter.convert()\n",
        "\n",
        "open('/content/drive/MyDrive/CMPE-258-Jagruti Mohanty/iris.tflite', 'wb').write(tfmodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6299 - acc: 0.2573\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1719 - acc: 0.2192\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1007 - acc: 0.2236\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0305 - acc: 0.2819\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9507 - acc: 0.5246\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9013 - acc: 0.5816\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8570 - acc: 0.5338\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7789 - acc: 0.6985\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7414 - acc: 0.7262\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7190 - acc: 0.6764\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6841 - acc: 0.6915\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6363 - acc: 0.7304\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6368 - acc: 0.7642\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7190 - acc: 0.5711\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5714 - acc: 0.7107\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5763 - acc: 0.7309\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5448 - acc: 0.7636\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5393 - acc: 0.8702\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5245 - acc: 0.7406\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5033 - acc: 0.8827\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4846 - acc: 0.7916\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4914 - acc: 0.8356\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4676 - acc: 0.8644\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4664 - acc: 0.9393\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4311 - acc: 0.8574\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4602 - acc: 0.8138\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4556 - acc: 0.8007\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4030 - acc: 0.7632\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4014 - acc: 0.8809\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4227 - acc: 0.8985\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4070 - acc: 0.9412\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3850 - acc: 0.8755\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3906 - acc: 0.9377\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3842 - acc: 0.9391\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3986 - acc: 0.9469\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4046 - acc: 0.9089\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3538 - acc: 0.9559\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3399 - acc: 0.9413\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3446 - acc: 0.9644\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3518 - acc: 0.9610\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3367 - acc: 0.9536\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3250 - acc: 0.9820\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3675 - acc: 0.8803\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3311 - acc: 0.9527\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3180 - acc: 0.9623\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3238 - acc: 0.9283\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3050 - acc: 0.9475\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2898 - acc: 0.9517\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2947 - acc: 0.9819\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.3182 - acc: 0.9344\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2969 - acc: 0.9535\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2829 - acc: 0.9312\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2899 - acc: 0.9391\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2685 - acc: 0.9754\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2806 - acc: 0.9517\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2875 - acc: 0.9607\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2679 - acc: 0.9466\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2648 - acc: 0.9440\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2606 - acc: 0.9667\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2592 - acc: 0.9816\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2673 - acc: 0.9191\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2444 - acc: 0.9544\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2426 - acc: 0.9621\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2479 - acc: 0.9566\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2382 - acc: 0.9658\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2396 - acc: 0.9731\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2877 - acc: 0.8855\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2364 - acc: 0.9575\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2492 - acc: 0.9772\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2017 - acc: 0.9636\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2073 - acc: 0.9683\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2264 - acc: 0.9440\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2464 - acc: 0.9404\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1968 - acc: 0.9863\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2006 - acc: 0.9683\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2192 - acc: 0.9741\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1993 - acc: 0.9715\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1937 - acc: 0.9728\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1928 - acc: 0.9580\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2030 - acc: 0.9807\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2071 - acc: 0.9706\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1835 - acc: 0.9741\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2048 - acc: 0.9493\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1822 - acc: 0.9876\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1802 - acc: 0.9746\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1817 - acc: 0.9754\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1908 - acc: 0.9703\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1799 - acc: 0.9584\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1935 - acc: 0.9663\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1614 - acc: 0.9731\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1787 - acc: 0.9790\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1536 - acc: 0.9597\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1749 - acc: 0.9685\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1680 - acc: 0.9626\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1423 - acc: 0.9863\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1854 - acc: 0.9454\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1557 - acc: 0.9723\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1651 - acc: 0.9602\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1615 - acc: 0.9824\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1758 - acc: 0.9423\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1489 - acc: 0.9767\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1633 - acc: 0.9712\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1682 - acc: 0.9755\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1662 - acc: 0.9728\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1617 - acc: 0.9528\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1525 - acc: 0.9676\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1550 - acc: 0.9487\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1423 - acc: 0.9841\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1751 - acc: 0.9396\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1345 - acc: 0.9793\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1432 - acc: 0.9798\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1563 - acc: 0.9824\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1484 - acc: 0.9628\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1711 - acc: 0.9449\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1210 - acc: 0.9833\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1461 - acc: 0.9781\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1551 - acc: 0.9833\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1244 - acc: 0.9772\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1323 - acc: 0.9733\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1519 - acc: 0.9555\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1335 - acc: 0.9899\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1559 - acc: 0.9518\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1415 - acc: 0.9785\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1431 - acc: 0.9506\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1430 - acc: 0.9741\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1355 - acc: 0.9828\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1280 - acc: 0.9781\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1302 - acc: 0.9712\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1256 - acc: 0.9732\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1168 - acc: 0.9933\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1336 - acc: 0.9659\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1180 - acc: 0.9863\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1267 - acc: 0.9781\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1194 - acc: 0.9700\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1503 - acc: 0.9309\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1137 - acc: 0.9560\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1220 - acc: 0.9718\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1207 - acc: 0.9780\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1272 - acc: 0.9754\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1206 - acc: 0.9702\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1134 - acc: 0.9609\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1232 - acc: 0.9703\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1302 - acc: 0.9676\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1125 - acc: 0.9654\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1082 - acc: 0.9868\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1103 - acc: 0.9780\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1537 - acc: 0.9607\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1145 - acc: 0.9801\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1053 - acc: 0.9718\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1078 - acc: 0.9733\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1194 - acc: 0.9847\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1313 - acc: 0.9644\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - acc: 0.9764\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1189 - acc: 0.9666\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1301 - acc: 0.9636\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1141 - acc: 0.9685\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1447 - acc: 0.9519\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1390 - acc: 0.9529\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1100 - acc: 0.9789\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1053 - acc: 0.9833\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1128 - acc: 0.9815\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0988 - acc: 0.9785\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0982 - acc: 0.9728\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1102 - acc: 0.9755\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1030 - acc: 0.9733\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1134 - acc: 0.9391\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1134 - acc: 0.9702\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1126 - acc: 0.9755\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1081 - acc: 0.9712\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1149 - acc: 0.9570\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0948 - acc: 0.9850\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1284 - acc: 0.9510\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0972 - acc: 0.9886\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1151 - acc: 0.9633\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0841 - acc: 0.9846\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1189 - acc: 0.9571\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1123 - acc: 0.9653\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1024 - acc: 0.9763\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0902 - acc: 0.9947\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1105 - acc: 0.9790\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0947 - acc: 0.9781\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1140 - acc: 0.9755\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0969 - acc: 0.9846\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1079 - acc: 0.9667\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0979 - acc: 0.9755\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0821 - acc: 0.9847\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0955 - acc: 0.9733\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0808 - acc: 0.9836\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0901 - acc: 0.9710\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1253 - acc: 0.9623\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1211 - acc: 0.9527\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0925 - acc: 0.9764\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1192 - acc: 0.9592\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1001 - acc: 0.9781\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0834 - acc: 0.9811\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0987 - acc: 0.9720\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1220 - acc: 0.9435\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1166 - acc: 0.9633\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1088 - acc: 0.9755\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0907 - acc: 0.9772\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpywj3xz0a/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpywj3xz0a/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20488"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YFnc-r20LzW"
      },
      "source": [
        "# This model is later on used in andriod application the details are shared in github repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ9j53QZVXlf"
      },
      "source": [
        "# Part D) Code is updated in github with evidence"
      ]
    }
  ]
}